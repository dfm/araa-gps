{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPWASdR_4Jts"
   },
   "source": [
    "# Gaussian Process Kernel Assessment\n",
    "\n",
    "We always tell people that they could use something like cross validation for kernel selection, but how do you actually do it?\n",
    "\n",
    "Let's work through it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wPltisWrJv2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import arviz as az\n",
    "import corner\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpyro\n",
    "import seaborn as sns\n",
    "from numpyro import distributions as dist\n",
    "from numpyro import infer\n",
    "from numpyro_ext.optim import optimize\n",
    "from tinygp import GaussianProcess, kernels\n",
    "\n",
    "from paths import figures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"ticks\")\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcou7n9r8tC6"
   },
   "source": [
    "Then we'll simulate some data using a GP with a known squared exponential kernel.\n",
    "When simulating, we'll choose to hold out some data as our \"test set\".\n",
    "For cross validation more generally we'd want to do this for many realizations of the left out data, but in the name of computational efficiency, we'll just do a single realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "h5g5l2IVrVj5",
    "outputId": "6ae5bacc-103b-4233-c17f-2479b3a6a499"
   },
   "outputs": [],
   "source": [
    "key_t, key_y, key_split = jax.random.split(jax.random.PRNGKey(100), 3)\n",
    "N = 120\n",
    "yerr = 0.25\n",
    "t = jnp.sort(jax.random.uniform(key_t, (N,), minval=0.0, maxval=10.0))\n",
    "\n",
    "kernel = 2.5**2 * kernels.ExpSquared(0.5)\n",
    "gp = GaussianProcess(kernel, t, diag=yerr**2)\n",
    "y = gp.sample(key_y)\n",
    "\n",
    "mask_train = jax.random.uniform(key_split, (N,)) < 0.6\n",
    "# mask_train = mask_train.at[:20].set(False)\n",
    "# mask_train = mask_train.at[-20:].set(False)\n",
    "\n",
    "plt.plot(t[mask_train], y[mask_train], \".k\", label=\"training data\")\n",
    "plt.plot(t[~mask_train], y[~mask_train], \"+C0\", label=\"held out data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3QwiIgi8zBP"
   },
   "source": [
    "Set up the probabilistic model to do MCMC for a range of different kernel models, optionally with different numbers of parameters.\n",
    "\n",
    "The likelihood for this model is the usual:\n",
    "\n",
    "$$\n",
    "y_\\mathrm{train} \\sim p(y_\\mathrm{train} | \\theta, \\phi) = \\mathcal{N}(m_\\theta, K_\\phi)\n",
    "$$\n",
    "\n",
    "Then, the validation likelihood is:\n",
    "\n",
    "$$\n",
    "y_\\mathrm{test} \\sim p(y_\\mathrm{test} | y_\\mathrm{train}, \\theta, \\phi) = \\mathcal{N}(m_\\star + K_\\star^\\mathrm{T} K^{-1}(y_\\mathrm{train} - m_\\theta), K_{\\star\\star} - K_\\star^\\mathrm{T} K^{-1} K_\\star)\n",
    "$$\n",
    "\n",
    "where the mean and covariance are the usual predictive distributions.\n",
    "Importantly $K_{\\star\\star}$ should include the observational uncertainty for the test data on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9pjt4gNsL3J",
    "outputId": "ae2e6338-264e-4393-9856-b9949c32baf6"
   },
   "outputs": [],
   "source": [
    "def model(kernel_builder, t_train, y_train, t_test=None, y_test=None, t_pred=None):\n",
    "    gp = GaussianProcess(kernel_builder(), t_train, diag=yerr**2)\n",
    "    if t_test is None:\n",
    "        numpyro.sample(\"y_train\", gp.numpyro_dist(), obs=y_train)\n",
    "    else:\n",
    "        log_prob_train, gp_cond = gp.condition(y_train, t_test, diag=yerr**2)\n",
    "        log_prob_test = gp_cond.log_probability(y_test)\n",
    "        numpyro.factor(\"log_prob_train\", log_prob_train)\n",
    "        numpyro.deterministic(\"log_prob_test\", log_prob_test)\n",
    "\n",
    "    if t_pred is not None:\n",
    "        gp_pred = gp.condition(y_train, t_pred, diag=yerr**2).gp\n",
    "        numpyro.deterministic(\"mean_pred\", gp_pred.loc)\n",
    "        numpyro.deterministic(\"std_pred\", jnp.sqrt(gp_pred.variance))\n",
    "\n",
    "\n",
    "def build_exp_sq():\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(10.0))\n",
    "    rho = numpyro.sample(\"rho\", dist.HalfNormal(5.0))\n",
    "    return sigma**2 * kernels.ExpSquared(rho)\n",
    "\n",
    "\n",
    "def build_matern():\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(10.0))\n",
    "    rho = numpyro.sample(\"rho\", dist.HalfNormal(5.0))\n",
    "    return sigma**2 * kernels.Matern32(rho)\n",
    "\n",
    "\n",
    "def build_raquad():\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(10.0))\n",
    "    rho = numpyro.sample(\"rho\", dist.HalfNormal(5.0))\n",
    "    alpha = numpyro.sample(\"alpha\", dist.HalfNormal(10.0))\n",
    "    return sigma**2 * kernels.RationalQuadratic(rho, alpha=alpha)\n",
    "\n",
    "\n",
    "sampler_exp_sq = infer.MCMC(\n",
    "    infer.NUTS(partial(model, build_exp_sq), dense_mass=True, target_accept_prob=0.9),\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    "    chain_method=\"sequential\",\n",
    ")\n",
    "sampler_matern = infer.MCMC(\n",
    "    infer.NUTS(partial(model, build_matern), dense_mass=True, target_accept_prob=0.9),\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    "    chain_method=\"sequential\",\n",
    ")\n",
    "sampler_raquad = infer.MCMC(\n",
    "    infer.NUTS(partial(model, build_raquad), dense_mass=True, target_accept_prob=0.9),\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    "    chain_method=\"sequential\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred = jnp.linspace(-1, 11, 500)\n",
    "mod = partial(model, build_matern)\n",
    "soln = optimize(mod)(jax.random.PRNGKey(0), t[mask_train], y[mask_train], t_pred=t_pred)\n",
    "samp = infer.Predictive(mod, soln)(\n",
    "    jax.random.PRNGKey(0), t[mask_train], y[mask_train], t_pred=t_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "VvjHeSzy19re",
    "outputId": "9001ad9b-7184-4368-c6b8-e85a1c3d7999"
   },
   "outputs": [],
   "source": [
    "sampler_exp_sq.run(\n",
    "    jax.random.PRNGKey(0), t[mask_train], y[mask_train], t[~mask_train], y[~mask_train]\n",
    ")\n",
    "inf_exp_sq = az.from_numpyro(sampler_exp_sq)\n",
    "corner.corner(inf_exp_sq)\n",
    "az.summary(inf_exp_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "6qdOSU8P2NAM",
    "outputId": "c20a962c-881d-468a-8587-f4476fef0db0"
   },
   "outputs": [],
   "source": [
    "sampler_matern.run(\n",
    "    jax.random.PRNGKey(0), t[mask_train], y[mask_train], t[~mask_train], y[~mask_train]\n",
    ")\n",
    "inf_matern = az.from_numpyro(sampler_matern)\n",
    "corner.corner(inf_matern)\n",
    "az.summary(inf_matern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 878
    },
    "id": "YxJd3b4g5Byy",
    "outputId": "b4864fd3-9386-4910-81eb-e8b731ca462c"
   },
   "outputs": [],
   "source": [
    "sampler_raquad.run(\n",
    "    jax.random.PRNGKey(0), t[mask_train], y[mask_train], t[~mask_train], y[~mask_train]\n",
    ")\n",
    "inf_raquad = az.from_numpyro(sampler_raquad)\n",
    "corner.corner(inf_raquad)\n",
    "az.summary(inf_raquad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "u9WcUa8n2Ret",
    "outputId": "bacf171e-7d52-449a-e4ff-1354f47254b6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(\n",
    "    inf_exp_sq.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"squared exp.\",\n",
    "    density=True,\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.hist(\n",
    "    inf_raquad.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"rational quad.\",\n",
    "    density=True,\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.hist(\n",
    "    inf_matern.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"Matérn-3/2\",\n",
    "    density=True,\n",
    "    linestyle=\"dotted\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.yticks([])\n",
    "plt.ylabel(\"posterior density\")\n",
    "plt.xlabel(\"log probability of held out data\")\n",
    "plt.xlim(-40, -29);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGcCuQy3BjsM",
    "outputId": "5d3ccbe3-dd23-4ce0-8221-5f556f16667b"
   },
   "outputs": [],
   "source": [
    "from numpyro.contrib.nested_sampling import NestedSampler\n",
    "\n",
    "ns_exp_sq = NestedSampler(partial(model, build_exp_sq))\n",
    "ns_exp_sq.run(jax.random.PRNGKey(0), t, y)\n",
    "ns_exp_sq._results.log_Z_mean, ns_exp_sq._results.log_Z_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MV4B3ofBvpN",
    "outputId": "5d70a95d-cdeb-4082-de68-c4bf879e798c"
   },
   "outputs": [],
   "source": [
    "ns_matern = NestedSampler(partial(model, build_matern))\n",
    "ns_matern.run(jax.random.PRNGKey(0), t, y)\n",
    "ns_matern._results.log_Z_mean, ns_matern._results.log_Z_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtg8cj00DjgQ",
    "outputId": "39b3c3d6-ec75-40f4-ea58-98982f171846"
   },
   "outputs": [],
   "source": [
    "ns_raquad = NestedSampler(partial(model, build_raquad))\n",
    "ns_raquad.run(jax.random.PRNGKey(0), t, y)\n",
    "ns_raquad._results.log_Z_mean, ns_raquad._results.log_Z_uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIfM5lznE_kA"
   },
   "outputs": [],
   "source": [
    "log_Z = [\n",
    "    ns_exp_sq._results.log_Z_mean,\n",
    "    ns_raquad._results.log_Z_mean,\n",
    "    ns_matern._results.log_Z_mean,\n",
    "]\n",
    "log_Z_uncert = [\n",
    "    ns_exp_sq._results.log_Z_uncert,\n",
    "    ns_raquad._results.log_Z_uncert,\n",
    "    ns_matern._results.log_Z_uncert,\n",
    "]\n",
    "names = [\"squared exp.\", \"rational quad.\", \"Matérn-3/2\"]\n",
    "\n",
    "plt.figure(figsize=(2, 5))\n",
    "plt.errorbar(names, log_Z, yerr=log_Z_uncert, fmt=\"o\")\n",
    "plt.xlim(-1, 3)\n",
    "[lbl.set_rotation(45) for lbl in plt.gca().get_xticklabels()]\n",
    "plt.ylabel(\"log(evidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplot_mosaic(\n",
    "    [[\"A\", \"B\", \"C\"]],\n",
    "    gridspec_kw={\"width_ratios\": [2.5, 1, 2], \"wspace\": 0.1},\n",
    "    constrained_layout=True,\n",
    "    figsize=(10, 4),\n",
    ")\n",
    "\n",
    "# Data\n",
    "ax = axes[\"A\"]\n",
    "ax.plot(t[mask_train], y[mask_train], \".k\", label=\"training\")\n",
    "ax.plot(t[~mask_train], y[~mask_train], \"+C0\", label=\"held out\")\n",
    "ax.plot(t_pred, samp[\"mean_pred\"], \"C1\", label=\"max. like.\", lw=0.5)\n",
    "ax.fill_between(\n",
    "    t_pred,\n",
    "    samp[\"mean_pred\"] - samp[\"std_pred\"],\n",
    "    samp[\"mean_pred\"] + samp[\"std_pred\"],\n",
    "    color=\"C1\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"data\")\n",
    "\n",
    "# Evidence\n",
    "ax = axes[\"B\"]\n",
    "log_Z = [\n",
    "    ns_exp_sq._results.log_Z_mean,\n",
    "    ns_raquad._results.log_Z_mean,\n",
    "    ns_matern._results.log_Z_mean,\n",
    "]\n",
    "log_Z_uncert = [\n",
    "    ns_exp_sq._results.log_Z_uncert,\n",
    "    ns_raquad._results.log_Z_uncert,\n",
    "    ns_matern._results.log_Z_uncert,\n",
    "]\n",
    "names = [\"squared exp.\", \"rational quad.\", \"Matérn-3/2\"]\n",
    "ax.errorbar(names, log_Z, yerr=log_Z_uncert, fmt=\"ok\")\n",
    "ax.set_xlim(-1, 3)\n",
    "[lbl.set_rotation(45) for lbl in ax.get_xticklabels()]\n",
    "ax.set_ylabel(\"log(evidence)\")\n",
    "ax.set_title(\"Bayesian evidence\")\n",
    "\n",
    "# Cross validation\n",
    "ax = axes[\"C\"]\n",
    "ax.hist(\n",
    "    inf_exp_sq.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"squared exp.\",\n",
    "    density=True,\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.hist(\n",
    "    inf_raquad.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"rational quad.\",\n",
    "    density=True,\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.hist(\n",
    "    inf_matern.posterior[\"log_prob_test\"].values.flatten(),\n",
    "    50,\n",
    "    histtype=\"step\",\n",
    "    label=\"Matérn-3/2\",\n",
    "    density=True,\n",
    "    linestyle=\"dotted\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel(\"posterior density\")\n",
    "ax.set_xlabel(\"log probability of held out data\")\n",
    "ax.set_xlim(-40, -29)\n",
    "ax.set_title(\"posterior predictive assessment\")\n",
    "\n",
    "plt.savefig(figures / \"assessment.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gaussian Process Cross Validation for Kernel Selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('araa-gps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "37131511e6302b4c680d7a9231cad616a6dbde5e3e7bdd137309d00c60a9825b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
